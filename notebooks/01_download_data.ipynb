# Notebook 01 â€” Descarga y PreparaciÃ³n del Dataset de HÃ­gado

# ---------------------------------------------------------------------
# Este notebook servirÃ¡ para:
# 1. Descargar el dataset seleccionado (Tabula Muris Senis â€” liver)
# 2. Hacer una inspecciÃ³n inicial de los metadatos
# 3. Guardar el dataset procesado en /data/raw y /data/processed
# ---------------------------------------------------------------------

# âš™ï¸ Dependencias iniciales
import os
import scanpy as sc
import pandas as pd

# Crear carpetas base si no existen
base_dirs = ["data", "data/raw", "data/processed", "notebooks"]
for d in base_dirs:
    os.makedirs(d, exist_ok=True)

# ğŸ“¥ Descarga del dataset
# Usamos el dataset liver de Tabula Muris Senis desde su bucket pÃºblico
# NOTA: En este notebook simplemente preparamos el cÃ³digo; la ejecuciÃ³n real
# se harÃ¡ cuando corras este archivo en tu entorno.

url_liver = "https://s3.amazonaws.com/czbiohub-tabula-muris-senis/TM_senis_liver.h5ad"
raw_path = "data/raw/liver_raw.h5ad"

# Descarga con requests (solo si no existe)
import requests

if not os.path.exists(raw_path):
    print("Descargando dataset de hÃ­gado...")
    r = requests.get(url_liver)
    with open(raw_path, "wb") as f:
        f.write(r.content)
    print("Descarga completada.")
else:
    print("Dataset ya existe en data/raw.")

# ğŸ“‚ Cargar datos
adata = sc.read_h5ad(raw_path)
print(adata)

# ğŸ” InspecciÃ³n bÃ¡sica
print("\nColumnas del obs:")
print(adata.obs.columns)

print("\nPrimeras filas del obs:")
print(adata.obs.head())

# Guardar copia procesada inicial
processed_path = "data/processed/liver_initial.h5ad"
adata.write(processed_path)

print(f"\nDataset procesado guardado en {processed_path}")
